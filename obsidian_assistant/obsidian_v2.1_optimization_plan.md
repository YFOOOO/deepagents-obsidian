# Obsidian åŠ©æ‰‹ V2.1 ä¼˜åŒ–æ–¹æ¡ˆ

**åˆ›å»ºæ—¥æœŸ**: 2025-11-13  
**å½“å‰ç‰ˆæœ¬**: V2.0  
**ç›®æ ‡ç‰ˆæœ¬**: V2.1  
**ä¼˜åŒ–ç›®æ ‡**: é™ä½ Token æ¶ˆè€—ï¼Œæå‡å“åº”é€Ÿåº¦ï¼Œä¼˜åŒ–æˆæœ¬æ•ˆç›Š

---

## ğŸ“Š V2.0 æ€§èƒ½åŸºå‡†æµ‹è¯•

### æµ‹è¯•ç¯å¢ƒ
- **æ¨¡å‹**: ChatTongyi (qwen-turbo)
- **å®šä»·**: è¾“å…¥ Â¥0.002/1K tokens, è¾“å‡º Â¥0.006/1K tokens
- **æµ‹è¯•æ—¶é—´**: 2025-11-13
- **æµ‹è¯•æ ·æœ¬**: 3ä¸ªå…¸å‹åœºæ™¯

### æµ‹è¯•ç»“æœ

| åœºæ™¯ | å“åº”æ—¶é—´ | Token æ¶ˆè€— | æˆæœ¬ | è¯´æ˜ |
|------|----------|-----------|------|------|
| çº¯æœ¬åœ°æœç´¢ | 4.31s | 512 | Â¥0.0030 | Obsidian çŸ¥è¯†åº“æŸ¥è¯¢ |
| ç½‘é¡µæœç´¢ | 14.22s | 1,232 | Â¥0.0073 | ä½¿ç”¨è§¦å‘å…³é”®è¯ï¼ˆ"æ¨è"/"æœ€æ–°"ï¼‰ |
| æ··åˆæœç´¢ | 3.55s | 515 | Â¥0.0030 | ä¼˜å…ˆæœ¬åœ°ï¼ŒæŒ‰éœ€è¡¥å……ç½‘é¡µ |

**æ€»è®¡**: 3æ¬¡è°ƒç”¨ï¼Œ22.07ç§’ï¼Œ2,259 tokensï¼ŒÂ¥0.0133

### å…³é”®å‘ç°

1. **æ€§èƒ½å·®å¼‚æ˜¾è‘—**
   - ç½‘é¡µæœç´¢ tokens æ¶ˆè€—æ˜¯æœ¬åœ°æœç´¢çš„ **2.4å€**
   - ç½‘é¡µæœç´¢å“åº”æ—¶é—´æ˜¯æœ¬åœ°æœç´¢çš„ **3.3å€**
   
2. **æˆæœ¬é¢„ä¼°**ï¼ˆæŒ‰æ¯å¤©100æ¬¡æŸ¥è¯¢ï¼‰
   - çº¯æœ¬åœ°æ¨¡å¼: Â¥9/æœˆ
   - çº¯ç½‘é¡µæ¨¡å¼: Â¥22/æœˆ
   - æ··åˆæ¨¡å¼(70%æœ¬åœ°+30%ç½‘é¡µ): Â¥13/æœˆ

3. **ä¼˜åŒ–ç©ºé—´**
   - é‡å¤æŸ¥è¯¢æœªè¢«ç¼“å­˜
   - ç½‘é¡µæœç´¢ç»“æœå†—é•¿ï¼ˆå ç”¨å¤§é‡ tokensï¼‰
   - ç¼ºä¹æ™ºèƒ½è·¯ç”±æœºåˆ¶åˆ¤æ–­æ˜¯å¦éœ€è¦ç½‘é¡µæœç´¢

---

## ğŸš€ V2.1 ä¼˜åŒ–æ–¹æ¡ˆ

### æ–¹æ¡ˆ 1: æ™ºèƒ½è·¯ç”±å™¨ ğŸ¯

**ä¼˜å…ˆçº§**: ğŸ¥‡ P0 (æœ€é«˜)  
**éš¾åº¦**: â­â­ (ä¸­ç­‰)  
**é¢„æœŸæ”¶ç›Š**: 40-60% token èŠ‚çœ  
**é€‚ç”¨åœºæ™¯**: æ‰€æœ‰æŸ¥è¯¢

#### è®¾è®¡æ€è·¯
é€šè¿‡è¯­ä¹‰åˆ†æå’Œå…³é”®è¯æ£€æµ‹ï¼Œè‡ªåŠ¨åˆ¤æ–­æŸ¥è¯¢çš„æœ€ä¼˜æœç´¢ç­–ç•¥ï¼š
- **æœ¬åœ°ä¼˜å…ˆ**: åŸºç¡€çŸ¥è¯†ã€æ“ä½œæŒ‡å—ã€å·²æœ‰æ–‡æ¡£
- **ç½‘é¡µä¼˜å…ˆ**: æ—¶æ•ˆæ€§ä¿¡æ¯ã€æœ€æ–°åŠ¨æ€ã€æœªè¦†ç›–å†…å®¹
- **æ··åˆæ¨¡å¼**: éœ€è¦æœ¬åœ°+ç½‘é¡µç»¼åˆä¿¡æ¯

#### å®ç°ä»£ç æ¡†æ¶

```python
class SmartRouter:
    """æ™ºèƒ½è·¯ç”±å™¨ - è‡ªåŠ¨é€‰æ‹©æœ€ä¼˜æœç´¢ç­–ç•¥"""
    
    def __init__(self, obsidian_path: str):
        self.obsidian_path = obsidian_path
        self.time_sensitive_keywords = ["æœ€æ–°", "2025", "2024", "æ¨è", "ç°åœ¨", "ä»Šå¹´"]
        self.local_knowledge_base = self._build_local_index()
    
    def route(self, query: str) -> str:
        """
        è·¯ç”±å†³ç­–
        Returns: "local_only" | "web_first" | "hybrid"
        """
        # 1. æ£€æµ‹æ—¶æ•ˆæ€§éœ€æ±‚
        if self._is_time_sensitive(query):
            return "web_first"
        
        # 2. æ£€æµ‹æœ¬åœ°çŸ¥è¯†è¦†ç›–ç‡
        coverage_score = self._check_local_coverage(query)
        
        if coverage_score > 0.8:
            return "local_only"  # é«˜è¦†ç›–ï¼Œçº¯æœ¬åœ°
        elif coverage_score > 0.4:
            return "hybrid"      # ä¸­ç­‰è¦†ç›–ï¼Œæ··åˆæ¨¡å¼
        else:
            return "web_first"   # ä½è¦†ç›–ï¼Œç½‘é¡µä¼˜å…ˆ
    
    def _is_time_sensitive(self, query: str) -> bool:
        """æ£€æµ‹æ˜¯å¦éœ€è¦æœ€æ–°ä¿¡æ¯"""
        return any(keyword in query for keyword in self.time_sensitive_keywords)
    
    def _check_local_coverage(self, query: str) -> float:
        """è®¡ç®—æœ¬åœ°çŸ¥è¯†åº“è¦†ç›–ç‡ (0.0-1.0)"""
        keywords = self._extract_keywords(query)
        matched_count = sum(1 for kw in keywords if kw in self.local_knowledge_base)
        return matched_count / len(keywords) if keywords else 0.0
    
    def _build_local_index(self) -> set:
        """æ„å»ºæœ¬åœ°çŸ¥è¯†åº“ç´¢å¼•"""
        # æ‰«æ Obsidian æ–‡æ¡£ï¼Œæå–å…³é”®è¯
        # å®ç°: è¯»å–æ‰€æœ‰ .md æ–‡ä»¶ï¼Œæå–æ ‡é¢˜å’Œå…³é”®è¯
        pass
    
    def _extract_keywords(self, text: str) -> list:
        """æå–æŸ¥è¯¢å…³é”®è¯"""
        # ç®€å•å®ç°ï¼šåˆ†è¯ + å»åœç”¨è¯
        import re
        words = re.findall(r'\w+', text.lower())
        stopwords = {'çš„', 'æ˜¯', 'åœ¨', 'äº†', 'æœ‰', 'å’Œ', 'å°±', 'ä¸', 'the', 'is', 'a', 'an'}
        return [w for w in words if w not in stopwords and len(w) > 1]
```

#### é›†æˆåˆ° V2.1

```python
def create_obsidian_assistant_v21(
    model_name: str = "qwen-turbo",
    obsidian_path: str = DEFAULT_OBSIDIAN_PATH,
    enable_smart_routing: bool = True  # æ–°å¢å‚æ•°
):
    """åˆ›å»ºå¸¦æ™ºèƒ½è·¯ç”±çš„ Obsidian åŠ©æ‰‹ V2.1"""
    
    # åˆå§‹åŒ–æ™ºèƒ½è·¯ç”±å™¨
    router = SmartRouter(obsidian_path) if enable_smart_routing else None
    
    # ä¿®æ”¹æç¤ºè¯ï¼ŒåŠ å…¥è·¯ç”±ç­–ç•¥è¯´æ˜
    enhanced_prompt = OBSIDIAN_ASSISTANT_PROMPT_V2 + """

## æ™ºèƒ½è·¯ç”±ç­–ç•¥ (V2.1)
æ ¹æ®æŸ¥è¯¢ç±»å‹ï¼Œç³»ç»Ÿä¼šè‡ªåŠ¨é€‰æ‹©æœ€ä¼˜æœç´¢ç­–ç•¥ï¼š
- **æœ¬åœ°ä¼˜å…ˆ**: å¯¹äºåŸºç¡€æ“ä½œã€å·²æœ‰æ–‡æ¡£çš„æŸ¥è¯¢ï¼Œç›´æ¥ä½¿ç”¨æœ¬åœ°çŸ¥è¯†åº“
- **ç½‘é¡µä¼˜å…ˆ**: å¯¹äº"æœ€æ–°"ã€"æ¨è"ç­‰æ—¶æ•ˆæ€§éœ€æ±‚ï¼Œä¼˜å…ˆç½‘é¡µæœç´¢
- **æ··åˆæ¨¡å¼**: éœ€è¦ç»¼åˆæœ¬åœ°+ç½‘é¡µä¿¡æ¯æ—¶ï¼ŒæŒ‰éœ€ç»„åˆ
"""
    
    # ... (å…¶ä»–ä»£ç ä¿æŒä¸å˜)
    
    return agent_executor
```

#### é¢„æœŸæ•ˆæœ
- é¿å…ä¸å¿…è¦çš„ç½‘é¡µæœç´¢è°ƒç”¨ï¼ˆèŠ‚çœ 14ç§’å“åº”æ—¶é—´ï¼‰
- æœ¬åœ°èƒ½è§£å†³çš„é—®é¢˜ä¸è§¦å‘å­ä»£ç†ï¼ˆèŠ‚çœ ~700 tokensï¼‰
- æ•´ä½“ token æ¶ˆè€—é™ä½ **40-60%**

---

### æ–¹æ¡ˆ 2: å¤šçº§ç¼“å­˜ç³»ç»Ÿ ğŸ†

**ä¼˜å…ˆçº§**: ğŸ¥ˆ P1 (é«˜)  
**éš¾åº¦**: â­â­â­ (è¾ƒéš¾)  
**é¢„æœŸæ”¶ç›Š**: 80% token èŠ‚çœ (é’ˆå¯¹é‡å¤æŸ¥è¯¢)  
**é€‚ç”¨åœºæ™¯**: é«˜é¢‘é—®é¢˜ã€é‡å¤æŸ¥è¯¢

#### è®¾è®¡æ€è·¯
å»ºç«‹ä¸‰çº§ç¼“å­˜ä½“ç³»ï¼š
1. **å†…å­˜ç¼“å­˜**: ç§’çº§å“åº”ï¼Œå½“å‰ä¼šè¯æœ‰æ•ˆ
2. **ç£ç›˜ç¼“å­˜**: è·¨ä¼šè¯æŒä¹…åŒ–ï¼Œ1å°æ—¶ TTL
3. **è¯­ä¹‰ç¼“å­˜**: ç›¸ä¼¼é—®é¢˜å‘½ä¸­ï¼ˆæœªæ¥æ‰©å±•ï¼‰

#### å®ç°ä»£ç æ¡†æ¶

```python
import json
import hashlib
from pathlib import Path
from datetime import datetime, timedelta

class CachedObsidianAssistant:
    """å¸¦å¤šçº§ç¼“å­˜çš„ Obsidian åŠ©æ‰‹"""
    
    def __init__(self, base_assistant, cache_dir: str = ".cache"):
        self.assistant = base_assistant
        self.cache_dir = Path(cache_dir)
        self.cache_dir.mkdir(exist_ok=True)
        
        # å†…å­˜ç¼“å­˜
        self.memory_cache = {}
        
        # ç¼“å­˜é…ç½®
        self.ttl_seconds = 3600  # 1å°æ—¶è¿‡æœŸ
    
    def query(self, question: str) -> dict:
        """å¸¦ç¼“å­˜çš„æŸ¥è¯¢"""
        cache_key = self._get_cache_key(question)
        
        # 1. æ£€æŸ¥å†…å­˜ç¼“å­˜
        if cache_key in self.memory_cache:
            print("ğŸš€ å‘½ä¸­å†…å­˜ç¼“å­˜")
            return self.memory_cache[cache_key]
        
        # 2. æ£€æŸ¥ç£ç›˜ç¼“å­˜
        cached_result = self._load_from_disk(cache_key)
        if cached_result and not self._is_expired(cached_result):
            print(f"ğŸ’¾ å‘½ä¸­ç£ç›˜ç¼“å­˜ (ç¼“å­˜äº {cached_result['cached_at']})")
            self.memory_cache[cache_key] = cached_result
            return cached_result
        
        # 3. å®é™…æŸ¥è¯¢
        print("ğŸ” ç¼“å­˜æœªå‘½ä¸­ï¼Œæ‰§è¡Œå®é™…æŸ¥è¯¢...")
        result = self.assistant.invoke({"messages": [("user", question)]})
        
        # 4. ä¿å­˜ç¼“å­˜
        cached_data = {
            "question": question,
            "result": result,
            "cached_at": datetime.now().isoformat(),
            "expires_at": (datetime.now() + timedelta(seconds=self.ttl_seconds)).isoformat()
        }
        self._save_to_disk(cache_key, cached_data)
        self.memory_cache[cache_key] = cached_data
        
        return cached_data
    
    def _get_cache_key(self, question: str) -> str:
        """ç”Ÿæˆç¼“å­˜é”®ï¼ˆMD5å“ˆå¸Œï¼‰"""
        return hashlib.md5(question.encode('utf-8')).hexdigest()
    
    def _load_from_disk(self, cache_key: str) -> dict:
        """ä»ç£ç›˜åŠ è½½ç¼“å­˜"""
        cache_file = self.cache_dir / f"{cache_key}.json"
        if cache_file.exists():
            try:
                with open(cache_file, 'r', encoding='utf-8') as f:
                    return json.load(f)
            except Exception as e:
                print(f"âš ï¸ ç¼“å­˜åŠ è½½å¤±è´¥: {e}")
        return None
    
    def _save_to_disk(self, cache_key: str, data: dict):
        """ä¿å­˜ç¼“å­˜åˆ°ç£ç›˜"""
        cache_file = self.cache_dir / f"{cache_key}.json"
        try:
            with open(cache_file, 'w', encoding='utf-8') as f:
                json.dump(data, f, ensure_ascii=False, indent=2)
        except Exception as e:
            print(f"âš ï¸ ç¼“å­˜ä¿å­˜å¤±è´¥: {e}")
    
    def _is_expired(self, cached_data: dict) -> bool:
        """æ£€æŸ¥ç¼“å­˜æ˜¯å¦è¿‡æœŸ"""
        expires_at = datetime.fromisoformat(cached_data['expires_at'])
        return datetime.now() > expires_at
    
    def clear_cache(self):
        """æ¸…ç©ºæ‰€æœ‰ç¼“å­˜"""
        self.memory_cache.clear()
        for cache_file in self.cache_dir.glob("*.json"):
            cache_file.unlink()
        print("ğŸ—‘ï¸ ç¼“å­˜å·²æ¸…ç©º")
```

#### ä½¿ç”¨ç¤ºä¾‹

```python
# åˆ›å»ºå¸¦ç¼“å­˜çš„åŠ©æ‰‹
base_assistant = create_obsidian_assistant_v21()
cached_assistant = CachedObsidianAssistant(base_assistant)

# ç¬¬ä¸€æ¬¡æŸ¥è¯¢ï¼ˆå®é™…è°ƒç”¨ LLMï¼‰
result1 = cached_assistant.query("å¦‚ä½•åˆ›å»ºåŒå‘é“¾æ¥ï¼Ÿ")

# ç¬¬äºŒæ¬¡ç›¸åŒæŸ¥è¯¢ï¼ˆå‘½ä¸­ç¼“å­˜ï¼Œ0 tokensï¼‰
result2 = cached_assistant.query("å¦‚ä½•åˆ›å»ºåŒå‘é“¾æ¥ï¼Ÿ")
```

#### é¢„æœŸæ•ˆæœ
- é‡å¤æŸ¥è¯¢ **0 tokens** æ¶ˆè€—
- å“åº”æ—¶é—´ä» 4ç§’é™è‡³ **<0.1ç§’**
- é’ˆå¯¹é«˜é¢‘é—®é¢˜ï¼ˆFAQï¼‰ï¼ŒèŠ‚çœ **80%+ tokens**

---

### æ–¹æ¡ˆ 3: ç»“æœå‹ç¼©ä¸æ‘˜è¦ ğŸ“¦

**ä¼˜å…ˆçº§**: ğŸ¥‰ P2 (ä¸­)  
**éš¾åº¦**: â­â­â­â­ (å›°éš¾)  
**é¢„æœŸæ”¶ç›Š**: 30-50% token èŠ‚çœ (é’ˆå¯¹ç½‘é¡µæœç´¢)  
**é€‚ç”¨åœºæ™¯**: ç½‘é¡µæœç´¢ç»“æœå¤„ç†

#### è®¾è®¡æ€è·¯
ç½‘é¡µæœç´¢è¿”å›çš„å†…å®¹é€šå¸¸å†—é•¿ï¼ŒåŒ…å«å¤§é‡å†—ä½™ä¿¡æ¯ï¼š
- **é—®é¢˜**: æµ‹è¯• 2 æ˜¾ç¤ºç½‘é¡µæœç´¢æ¶ˆè€— 1,232 tokensï¼ˆæœ¬åœ°æœç´¢çš„ 2.4å€ï¼‰
- **è§£å†³æ–¹æ¡ˆ**: å¯¹ç½‘é¡µç»“æœè¿›è¡Œæ™ºèƒ½å‹ç¼©å’Œæ‘˜è¦

#### å®ç°ä»£ç æ¡†æ¶

```python
from typing import List
import re

class WebResultCompressor:
    """ç½‘é¡µæœç´¢ç»“æœå‹ç¼©å™¨"""
    
    def __init__(self, max_tokens_per_result: int = 150):
        self.max_tokens_per_result = max_tokens_per_result
    
    def compress(self, web_results: List[dict]) -> str:
        """å‹ç¼©ç½‘é¡µæœç´¢ç»“æœ"""
        if not web_results:
            return ""
        
        compressed_items = []
        
        for idx, result in enumerate(web_results[:5], 1):  # æœ€å¤šä¿ç•™5æ¡
            # 1. æå–å…³é”®ä¿¡æ¯
            title = result.get("title", "")
            url = result.get("url", "")
            content = result.get("content", "")
            
            # 2. å†…å®¹æ‘˜è¦ï¼ˆä¿ç•™å‰150ä¸ªå­—ç¬¦æˆ–æ ¸å¿ƒå¥å­ï¼‰
            summary = self._extract_key_sentences(content)
            
            # 3. æ ¼å¼åŒ–è¾“å‡º
            compressed_items.append(f"{idx}. **{title}**\n   {summary}\n   ğŸ”— {url}")
        
        return "\n\n".join(compressed_items)
    
    def _extract_key_sentences(self, text: str, max_length: int = 150) -> str:
        """æå–æ ¸å¿ƒå¥å­"""
        # ç®€å•å®ç°ï¼šå–å‰ä¸¤å¥è¯
        sentences = re.split(r'[ã€‚ï¼ï¼Ÿ.!?]\s*', text)
        result = []
        current_length = 0
        
        for sentence in sentences:
            if current_length + len(sentence) > max_length:
                break
            result.append(sentence)
            current_length += len(sentence)
        
        summary = 'ã€‚'.join(result)
        return summary + '...' if len(text) > current_length else summary
    
    def _deduplicate(self, results: List[dict]) -> List[dict]:
        """å»é™¤é‡å¤å†…å®¹"""
        seen_urls = set()
        unique_results = []
        
        for result in results:
            url = result.get("url", "")
            if url not in seen_urls:
                seen_urls.add(url)
                unique_results.append(result)
        
        return unique_results
```

#### é›†æˆåˆ°ç½‘é¡µæœç´¢å·¥å…·

```python
def internet_search_v21(query: str, compressor: WebResultCompressor) -> str:
    """V2.1 å¢å¼ºç‰ˆç½‘é¡µæœç´¢ï¼ˆå¸¦ç»“æœå‹ç¼©ï¼‰"""
    try:
        tavily = TavilySearchResults(
            max_results=5,
            search_depth="advanced",
            include_answer=True,
            include_raw_content=False  # å‡å°‘å†—ä½™å†…å®¹
        )
        
        results = tavily.invoke({"query": query})
        
        # ğŸ†• å‹ç¼©ç»“æœ
        compressed = compressor.compress(results)
        
        return f"""
### ç½‘é¡µæœç´¢ç»“æœ (å·²ä¼˜åŒ–)
{compressed}

ğŸ’¡ æç¤º: ä»¥ä¸Šå†…å®¹å·²è‡ªåŠ¨å‹ç¼©ï¼Œä»…ä¿ç•™æ ¸å¿ƒä¿¡æ¯
"""
    except Exception as e:
        return f"âš ï¸ ç½‘é¡µæœç´¢å‡ºé”™: {str(e)}"
```

#### é¢„æœŸæ•ˆæœ
- ç½‘é¡µæœç´¢ç»“æœ tokens ä» 1,232 é™è‡³ **600-800**
- ä¿ç•™æ ¸å¿ƒä¿¡æ¯ï¼Œå»é™¤å†—ä½™å†…å®¹
- å“åº”é€Ÿåº¦æå‡ï¼ˆæ›´å°‘ tokens éœ€è¦å¤„ç†ï¼‰

---

## ğŸ“‹ å®æ–½è·¯çº¿å›¾

### Phase 1: å¿«é€Ÿæ”¶ç›Š (1-2å¤©)
- [x] V2.0 åŸºå‡†æµ‹è¯•å®Œæˆ
- [x] Token è®¡æ•°å™¨é›†æˆ
- [ ] **å®æ–½æ™ºèƒ½è·¯ç”±å™¨** (æ–¹æ¡ˆ1) - æœ€å¿«è§æ•ˆ

### Phase 2: æ·±åº¦ä¼˜åŒ– (3-5å¤©)
- [ ] **å®æ–½å¤šçº§ç¼“å­˜** (æ–¹æ¡ˆ2) - æœ€å¤§æ”¶ç›Š
- [ ] ç¼“å­˜æ€§èƒ½æµ‹è¯•
- [ ] è°ƒä¼˜ TTL å’Œç¼“å­˜ç­–ç•¥

### Phase 3: ç²¾ç»†åŒ– (5-7å¤©)
- [ ] **å®æ–½ç»“æœå‹ç¼©** (æ–¹æ¡ˆ3)
- [ ] å‹ç¼©æ•ˆæœè¯„ä¼°
- [ ] A/B æµ‹è¯•å¯¹æ¯”

### Phase 4: ç›‘æ§ä¸è¿­ä»£ (æŒç»­)
- [ ] Token ä½¿ç”¨ç›‘æ§é¢æ¿
- [ ] æˆæœ¬é¢„è­¦æœºåˆ¶
- [ ] å®šæœŸæ€§èƒ½å›å½’æµ‹è¯•

---

## ğŸ¯ é¢„æœŸæ€»ä½“æ”¶ç›Š

| æŒ‡æ ‡ | V2.0 åŸºçº¿ | V2.1 é¢„æœŸ | æ”¹å–„å¹…åº¦ |
|------|-----------|-----------|----------|
| å¹³å‡å“åº”æ—¶é—´ | 7.36s | 4.5s | â¬‡ï¸ 39% |
| å¹³å‡ Token æ¶ˆè€— | 753 | 380 | â¬‡ï¸ 50% |
| æœˆåº¦æˆæœ¬ (100æ¬¡/å¤©) | Â¥13 | Â¥6.5 | â¬‡ï¸ 50% |
| ç¼“å­˜å‘½ä¸­ç‡ | 0% | 30-50% | â¬†ï¸ 50% |

---

## ğŸ“Š ç›‘æ§æŒ‡æ ‡

### å…³é”®æ€§èƒ½æŒ‡æ ‡ (KPIs)
1. **Token ä½¿ç”¨ç‡**: å•æ¬¡æŸ¥è¯¢ tokens / ç›®æ ‡é˜ˆå€¼ (500)
2. **ç¼“å­˜å‘½ä¸­ç‡**: ç¼“å­˜å‘½ä¸­æ¬¡æ•° / æ€»æŸ¥è¯¢æ¬¡æ•°
3. **è·¯ç”±å‡†ç¡®ç‡**: æ™ºèƒ½è·¯ç”±å†³ç­–æ­£ç¡®ç‡
4. **æˆæœ¬æ•ˆç›Š**: èŠ‚çœçš„æˆæœ¬ / æ€»æˆæœ¬

### ç›‘æ§å·¥å…·é›†æˆ
```python
class PerformanceMonitor:
    """æ€§èƒ½ç›‘æ§å™¨"""
    
    def __init__(self):
        self.metrics = {
            "total_queries": 0,
            "cache_hits": 0,
            "local_only_queries": 0,
            "web_search_queries": 0,
            "total_tokens": 0,
            "total_cost": 0.0
        }
    
    def log_query(self, query_type: str, tokens: int, cost: float, cache_hit: bool):
        """è®°å½•æŸ¥è¯¢æŒ‡æ ‡"""
        self.metrics["total_queries"] += 1
        self.metrics["total_tokens"] += tokens
        self.metrics["total_cost"] += cost
        
        if cache_hit:
            self.metrics["cache_hits"] += 1
        
        if query_type == "local":
            self.metrics["local_only_queries"] += 1
        elif query_type == "web":
            self.metrics["web_search_queries"] += 1
    
    def get_report(self) -> dict:
        """ç”Ÿæˆæ€§èƒ½æŠ¥å‘Š"""
        if self.metrics["total_queries"] == 0:
            return {}
        
        return {
            "cache_hit_rate": self.metrics["cache_hits"] / self.metrics["total_queries"],
            "avg_tokens": self.metrics["total_tokens"] / self.metrics["total_queries"],
            "avg_cost": self.metrics["total_cost"] / self.metrics["total_queries"],
            "web_search_ratio": self.metrics["web_search_queries"] / self.metrics["total_queries"]
        }
```

---

## ğŸ”§ é…ç½®å»ºè®®

### å¼€å‘ç¯å¢ƒé…ç½®
```python
# config_v21.py

V21_CONFIG = {
    # æ™ºèƒ½è·¯ç”±å™¨é…ç½®
    "routing": {
        "enabled": True,
        "local_coverage_threshold": 0.7,  # æœ¬åœ°è¦†ç›–ç‡é˜ˆå€¼
        "time_sensitive_keywords": ["æœ€æ–°", "æ¨è", "2025", "ç°åœ¨"]
    },
    
    # ç¼“å­˜é…ç½®
    "cache": {
        "enabled": True,
        "ttl_seconds": 3600,  # 1å°æ—¶
        "cache_dir": ".cache/obsidian",
        "max_cache_size_mb": 100  # æœ€å¤§ç¼“å­˜100MB
    },
    
    # å‹ç¼©é…ç½®
    "compression": {
        "enabled": True,
        "max_tokens_per_result": 150,
        "max_results": 5
    },
    
    # Token é¢„ç®—
    "budget": {
        "max_tokens_per_query": 800,  # å•æ¬¡æŸ¥è¯¢ä¸Šé™
        "daily_token_limit": 50000,   # æ¯æ—¥ token é™åˆ¶
        "alert_threshold": 0.8        # 80%æ—¶å‘é€è­¦å‘Š
    }
}
```

---

## ğŸ“š å‚è€ƒèµ„æº

1. **LangChain ç¼“å­˜æ–‡æ¡£**: https://python.langchain.com/docs/modules/model_io/llms/llm_caching
2. **Token ä¼˜åŒ–æœ€ä½³å®è·µ**: https://platform.openai.com/docs/guides/prompt-engineering
3. **Obsidian API æ–‡æ¡£**: https://github.com/obsidianmd/obsidian-api

---

## âœ… éªŒæ”¶æ ‡å‡†

### V2.1 ç‰ˆæœ¬å‘å¸ƒæ¡ä»¶
- [ ] æ™ºèƒ½è·¯ç”±å™¨å®ç°å¹¶é€šè¿‡å•å…ƒæµ‹è¯•
- [ ] ç¼“å­˜ç³»ç»Ÿå®ç°å¹¶éªŒè¯å‘½ä¸­ç‡ > 30%
- [ ] Token æ¶ˆè€—ç›¸æ¯” V2.0 é™ä½ > 40%
- [ ] æ‰€æœ‰åŸæœ‰åŠŸèƒ½æ­£å¸¸å·¥ä½œï¼ˆå›å½’æµ‹è¯•é€šè¿‡ï¼‰
- [ ] æ›´æ–°ç”¨æˆ·æ–‡æ¡£å’Œ README

---

**æ–‡æ¡£ç‰ˆæœ¬**: V2.1-PLAN-20251113  
**è´Ÿè´£äºº**: YF  
**å®¡æ ¸çŠ¶æ€**: å¾…å®æ–½
