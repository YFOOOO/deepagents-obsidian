"""
Token è®¡æ•°å™¨å·¥å…· v2.0 - å®æ—¶ç›‘æ§ LLM Token æ¶ˆè€—
- æ”¯æŒå¤šæ¨¡å‹ä»·æ ¼ç®¡ç†
- è‡ªåŠ¨ä»·æ ¼è¿‡æœŸæ£€æµ‹
- ä»·æ ¼æ•°æ®ç‰ˆæœ¬æ§åˆ¶
"""
import time
import warnings
from typing import Dict, Optional, Tuple
from dataclasses import dataclass, field
from datetime import datetime

@dataclass
class TokenUsage:
    timestamp: str
    question: str
    prompt_tokens: int
    completion_tokens: int
    total_tokens: int
    response_time: float
    model: str = "qwen-turbo"
    cost: float = 0.0

# ============================================================================
# ä»·æ ¼æ•°æ®åº“ (æ›´æ–°æ—¥æœŸ: 2025-11-14, æ¥æº: é˜¿é‡Œäº‘ç™¾ç‚¼å®˜æ–¹æ–‡æ¡£)
# å®˜æ–¹æ–‡æ¡£: https://help.aliyun.com/zh/model-studio/models
# ============================================================================

MODEL_PRICING = {
    # === Qwen ç³»åˆ— (é€šä¹‰åƒé—®) ===
    "qwen-turbo": {
        "input": 0.0003,   # Â¥0.3/ç™¾ä¸‡Token (å®é™…ä»·æ ¼)
        "output": 0.0006,  # Â¥0.6/ç™¾ä¸‡Token (éæ€è€ƒæ¨¡å¼)
        "description": "æé€Ÿç‰ˆï¼Œé€Ÿåº¦å¿«æˆæœ¬ä½",
        "context": "1M tokens",
        "updated": "2025-11-14"
    },
    "qwen-plus": {
        "input": 0.0008,   # Â¥0.8/ç™¾ä¸‡Token (0-128K)
        "output": 0.002,   # Â¥2/ç™¾ä¸‡Token (éæ€è€ƒæ¨¡å¼)
        "description": "å¹³è¡¡ç‰ˆï¼Œæ•ˆæœé€Ÿåº¦æˆæœ¬å‡è¡¡",
        "context": "1M tokens",
        "updated": "2025-11-14"
    },
    "qwen-max": {
        "input": 0.0032,   # Â¥3.2/ç™¾ä¸‡Token (0-32K) âš¡ å·²é™ä»·!
        "output": 0.0128,  # Â¥12.8/ç™¾ä¸‡Token
        "description": "æ——èˆ°ç‰ˆï¼Œèƒ½åŠ›æœ€å¼º (ä»·æ ¼å·²é™ä½47%)",
        "context": "262K tokens",
        "updated": "2025-11-14",
        "note": "2025å¹´11æœˆé™ä»·: ä»Â¥6/Â¥24é™è‡³Â¥3.2/Â¥12.8"
    },
    "qwen3-max": {
        "input": 0.0032,   # ä¸ qwen-max ç›¸åŒ
        "output": 0.0128,
        "description": "æœ€æ–°æ——èˆ°ç‰ˆ",
        "context": "262K tokens",
        "updated": "2025-11-14"
    },
    "qwen-long": {
        "input": 0.0005,   # Â¥0.5/ç™¾ä¸‡Token
        "output": 0.002,   # Â¥2/ç™¾ä¸‡Token
        "description": "è¶…é•¿æ–‡æ¡£ç‰ˆï¼Œ10Mä¸Šä¸‹æ–‡",
        "context": "10M tokens",
        "updated": "2025-11-14"
    },
    
    # === å¼€æºç‰ˆæœ¬ ===
    "qwen2.5-72b-instruct": {
        "input": 0.004,
        "output": 0.012,
        "description": "å¼€æº72Bæ¨¡å‹",
        "updated": "2025-11-14"
    },
    "qwen2.5-32b-instruct": {
        "input": 0.002,
        "output": 0.006,
        "description": "å¼€æº32Bæ¨¡å‹",
        "updated": "2025-11-14"
    },
    
    # === å…¶ä»–å‚å•†æ¨¡å‹ (ä¾›å‚è€ƒ) ===
    "deepseek-v3": {
        "input": 0.002,
        "output": 0.008,
        "description": "DeepSeek V3",
        "updated": "2025-11-14"
    },
    "kimi-k2": {
        "input": 0.004,
        "output": 0.016,
        "description": "Kimi K2",
        "updated": "2025-11-14"
    },
    "glm-4.5": {
        "input": 0.003,
        "output": 0.014,
        "description": "æ™ºè°± GLM-4.5",
        "updated": "2025-11-14"
    },
}

# ä»·æ ¼æ•°æ®ç‰ˆæœ¬ä¿¡æ¯
PRICING_VERSION = "2.0"
PRICING_LAST_UPDATE = "2025-11-14"
PRICING_SOURCE = "é˜¿é‡Œäº‘ç™¾ç‚¼å®˜æ–¹æ–‡æ¡£"
PRICING_WARNING_DAYS = 30  # è¶…è¿‡30å¤©æœªæ›´æ–°ä¼šè­¦å‘Š

# ============================================================================
# ä»·æ ¼ç®¡ç†å‡½æ•°
# ============================================================================

def check_pricing_freshness() -> Tuple[bool, int]:
    """æ£€æŸ¥ä»·æ ¼æ•°æ®æ˜¯å¦è¿‡æœŸ"""
    from datetime import datetime
    last_update = datetime.strptime(PRICING_LAST_UPDATE, "%Y-%m-%d")
    days_old = (datetime.now() - last_update).days
    is_fresh = days_old <= PRICING_WARNING_DAYS
    return is_fresh, days_old

def get_pricing_info(model: str = "qwen-turbo") -> Dict:
    """è·å–æ¨¡å‹ä»·æ ¼ä¿¡æ¯ï¼ˆå«å…ƒæ•°æ®ï¼‰"""
    if model not in MODEL_PRICING:
        warnings.warn(
            f"âš ï¸  æ¨¡å‹ '{model}' æœªåœ¨ä»·æ ¼åº“ä¸­ï¼Œä½¿ç”¨ qwen-turbo ä»·æ ¼ä½œä¸ºfallback",
            UserWarning
        )
        model = "qwen-turbo"
    return MODEL_PRICING[model]

def list_available_models() -> None:
    """åˆ—å‡ºæ‰€æœ‰æ”¯æŒçš„æ¨¡å‹åŠä»·æ ¼"""
    print("\n" + "=" * 100)
    print(f"ğŸ“‹ æ”¯æŒçš„æ¨¡å‹ä»·æ ¼è¡¨ (ç‰ˆæœ¬: {PRICING_VERSION}, æ›´æ–°: {PRICING_LAST_UPDATE})")
    print("=" * 100)
    
    categories = {
        "Qwen å•†ç”¨ç³»åˆ—": ["qwen-turbo", "qwen-plus", "qwen-max", "qwen3-max", "qwen-long"],
        "Qwen å¼€æºç³»åˆ—": ["qwen2.5-72b-instruct", "qwen2.5-32b-instruct"],
        "å…¶ä»–å‚å•†": ["deepseek-v3", "kimi-k2", "glm-4.5"]
    }
    
    for category, models in categories.items():
        print(f"\nğŸ·ï¸  {category}")
        print("-" * 100)
        for model in models:
            if model in MODEL_PRICING:
                info = MODEL_PRICING[model]
                print(f"  {model:25s} | è¾“å…¥: Â¥{info['input']:.4f}/k | è¾“å‡º: Â¥{info['output']:.4f}/k | {info['description']}")
    
    # æ£€æŸ¥ä»·æ ¼æ–°é²œåº¦
    is_fresh, days_old = check_pricing_freshness()
    if not is_fresh:
        print(f"\nâš ï¸  è­¦å‘Š: ä»·æ ¼æ•°æ®å·² {days_old} å¤©æœªæ›´æ–°ï¼Œå»ºè®®æ ¸å®æœ€æ–°ä»·æ ¼ï¼")
    print("=" * 100 + "\n")

def calculate_cost(prompt_tokens: int, completion_tokens: int, model: str = "qwen-turbo") -> float:
    """è®¡ç®—æˆæœ¬ï¼ˆå…ƒï¼‰"""
    pricing_info = get_pricing_info(model)
    return (prompt_tokens / 1000) * pricing_info["input"] + (completion_tokens / 1000) * pricing_info["output"]

def estimate_tokens(text: str) -> int:
    """ä¼°ç®—æ–‡æœ¬çš„ Token æ•°é‡ï¼ˆä¸­æ–‡å’Œè‹±æ–‡æ··åˆï¼‰"""
    chinese_chars = sum(1 for c in text if '\u4e00' <= c <= '\u9fff')
    english_words = len([w for w in text.split() if any(c.isalpha() for c in w)])
    return int(chinese_chars * 1.8 + english_words * 1.3) or len(text) // 4

def compare_model_costs(prompt_tokens: int, completion_tokens: int, models: list = None) -> None:
    """æ¯”è¾ƒä¸åŒæ¨¡å‹çš„æˆæœ¬"""
    if models is None:
        models = ["qwen-turbo", "qwen-plus", "qwen-max", "qwen3-max"]
    
    print("\n" + "=" * 80)
    print(f"ğŸ’° æˆæœ¬å¯¹æ¯” (è¾“å…¥: {prompt_tokens:,} tokens, è¾“å‡º: {completion_tokens:,} tokens)")
    print("=" * 80)
    
    results = []
    for model in models:
        if model in MODEL_PRICING:
            cost = calculate_cost(prompt_tokens, completion_tokens, model)
            info = MODEL_PRICING[model]
            results.append((model, cost, info['description']))
    
    # æŒ‰æˆæœ¬æ’åº
    results.sort(key=lambda x: x[1])
    
    for i, (model, cost, desc) in enumerate(results):
        icon = "ğŸ¥‡" if i == 0 else "ğŸ¥ˆ" if i == 1 else "ğŸ¥‰" if i == 2 else "  "
        print(f"{icon} {model:20s} | Â¥{cost:.4f} | {desc}")
    
    print("=" * 80 + "\n")

# ============================================================================
# TokenCounter ç±»
# ============================================================================

class TokenCounter:
    def __init__(self, model: str = "qwen-turbo"):
        self.model = model
        self.records = []
        self.current_start_time = None
        
        # å¯åŠ¨æ—¶æ£€æŸ¥ä»·æ ¼æ–°é²œåº¦
        is_fresh, days_old = check_pricing_freshness()
        if not is_fresh:
            warnings.warn(
                f"âš ï¸  ä»·æ ¼æ•°æ®å·² {days_old} å¤©æœªæ›´æ–° (æ›´æ–°äº: {PRICING_LAST_UPDATE})ï¼Œå»ºè®®æ ¸å®æœ€æ–°ä»·æ ¼ï¼",
                UserWarning
            )
    
    def start_counting(self):
        """å¼€å§‹è®¡æ—¶"""
        self.current_start_time = time.time()
    
    def record_usage(self, question: str, prompt_tokens: int, completion_tokens: int, model: Optional[str] = None) -> TokenUsage:
        """è®°å½•ä¸€æ¬¡è°ƒç”¨"""
        response_time = time.time() - self.current_start_time if self.current_start_time else 0
        model_name = model or self.model
        total = prompt_tokens + completion_tokens
        cost = calculate_cost(prompt_tokens, completion_tokens, model_name)
        
        record = TokenUsage(
            timestamp=datetime.now().strftime("%Y-%m-%d %H:%M:%S"),
            question=question[:50] + "..." if len(question) > 50 else question,
            prompt_tokens=prompt_tokens,
            completion_tokens=completion_tokens,
            total_tokens=total,
            response_time=response_time,
            model=model_name,
            cost=cost
        )
        self.records.append(record)
        return record
    
    def print_current_usage(self, record: TokenUsage):
        """æ‰“å°å•æ¬¡ä½¿ç”¨ç»Ÿè®¡"""
        pricing_info = get_pricing_info(record.model)
        
        print("\n" + "=" * 80)
        print("ğŸ“Š Token ä½¿ç”¨ç»Ÿè®¡")
        print("=" * 80)
        print(f"ğŸ• æ—¶é—´: {record.timestamp}")
        print(f"ğŸ¤– æ¨¡å‹: {record.model} ({pricing_info['description']})")
        print(f"â“ é—®é¢˜: {record.question}")
        print(f"â±ï¸  å“åº”æ—¶é—´: {record.response_time:.2f} ç§’")
        print(f"\nğŸ’¬ Token è¯¦æƒ…:")
        print(f"  - è¾“å…¥:  {record.prompt_tokens:>6,} tokens Ã— Â¥{pricing_info['input']:.4f}/k = Â¥{(record.prompt_tokens/1000)*pricing_info['input']:.4f}")
        print(f"  - è¾“å‡º:  {record.completion_tokens:>6,} tokens Ã— Â¥{pricing_info['output']:.4f}/k = Â¥{(record.completion_tokens/1000)*pricing_info['output']:.4f}")
        print(f"  - æ€»è®¡:  {record.total_tokens:>6,} tokens")
        print(f"\nğŸ’° æœ¬æ¬¡æˆæœ¬: Â¥{record.cost:.4f} å…ƒ")
        print("=" * 80 + "\n")
    
    def print_statistics(self):
        """æ‰“å°ç´¯ç§¯ç»Ÿè®¡"""
        if not self.records:
            print("âš ï¸  æš‚æ— ç»Ÿè®¡æ•°æ®")
            return
        
        total_tokens = sum(r.total_tokens for r in self.records)
        total_cost = sum(r.cost for r in self.records)
        total_time = sum(r.response_time for r in self.records)
        
        print("\n" + "=" * 80)
        print("ğŸ“ˆ ç´¯ç§¯ç»Ÿè®¡æŠ¥å‘Š")
        print("=" * 80)
        print(f"ğŸ“ æ€»è°ƒç”¨æ¬¡æ•°: {len(self.records)}")
        print(f"â±ï¸  æ€»å“åº”æ—¶é—´: {total_time:.2f} ç§’")
        print(f"âš¡ å¹³å‡å“åº”: {total_time/len(self.records):.2f} ç§’/æ¬¡")
        print(f"\nğŸ’¬ Token ç»Ÿè®¡:")
        print(f"  - ç´¯è®¡ Token: {total_tokens:>10,}")
        print(f"  - å¹³å‡ Token: {total_tokens/len(self.records):>10,.0f}")
        print(f"\nğŸ’° æˆæœ¬ç»Ÿè®¡:")
        print(f"  - ç´¯è®¡æˆæœ¬: Â¥{total_cost:.4f} å…ƒ")
        print(f"  - å¹³å‡æˆæœ¬: Â¥{total_cost/len(self.records):.4f} å…ƒ/æ¬¡")
        
        # æœˆåº¦é¢„ä¼°
        daily_100 = total_cost / len(self.records) * 100
        monthly = daily_100 * 30
        print(f"\nğŸ“Š ç”¨é‡é¢„ä¼° (æŒ‰å½“å‰æ¨¡å¼):")
        print(f"  - 100æ¬¡/å¤©: Â¥{daily_100:.2f}/å¤© â‰ˆ Â¥{monthly:.2f}/æœˆ")
        print("=" * 80 + "\n")

def count_tokens_for_result(question: str, result: dict, counter: TokenCounter) -> TokenUsage:
    """ä» agent ç»“æœä¸­è®¡ç®— Token æ¶ˆè€—"""
    total_input = estimate_tokens(question)
    total_output = 0
    
    messages = result.get("messages", [])
    for msg in messages:
        content = getattr(msg, 'content', None) or (msg.get('content', '') if isinstance(msg, dict) else str(msg))
        if content:
            total_output += estimate_tokens(str(content))
    
    return counter.record_usage(question, total_input, total_output)

# ============================================================================
# æ¨¡å—åˆå§‹åŒ–
# ============================================================================

print("=" * 80)
print("âœ… Token è®¡æ•°å™¨æ¨¡å— v2.0 åŠ è½½å®Œæˆ")
print("-" * 80)
print(f"ğŸ“¦ ä»·æ ¼åº“ç‰ˆæœ¬: {PRICING_VERSION}")
print(f"ğŸ“… æ•°æ®æ›´æ–°: {PRICING_LAST_UPDATE}")
print(f"ğŸ“š æ•°æ®æ¥æº: {PRICING_SOURCE}")
print(f"ğŸ”§ æ”¯æŒæ¨¡å‹: {len(MODEL_PRICING)} ä¸ª")

# æ£€æŸ¥ä»·æ ¼æ–°é²œåº¦
is_fresh, days_old = check_pricing_freshness()
if not is_fresh:
    print(f"âš ï¸  ä»·æ ¼æ•°æ®å·² {days_old} å¤©æœªæ›´æ–°ï¼Œå»ºè®®æ ¸å®æœ€æ–°ä»·æ ¼ï¼")
else:
    print(f"âœ… ä»·æ ¼æ•°æ®æ–°é²œ (æ›´æ–°äº {days_old} å¤©å‰)")

print("=" * 80)
print("\nğŸ’¡ æ–°åŠŸèƒ½:")
print("  - list_available_models()      # æŸ¥çœ‹æ‰€æœ‰æ”¯æŒçš„æ¨¡å‹")
print("  - compare_model_costs(...)     # å¯¹æ¯”ä¸åŒæ¨¡å‹æˆæœ¬")
print("  - get_pricing_info(model)      # è·å–æ¨¡å‹ä»·æ ¼è¯¦æƒ…")
print("\n")
