{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "072e0562",
   "metadata": {},
   "source": [
    "# Obsidian åŠ©æ‰‹ V2.1 éªŒè¯ Notebook\n",
    "\n",
    "ç›®æ ‡: å¯¹æ¯” Baseline ä¸ (æ™ºèƒ½è·¯ç”±+æ¨¡å‹é€‚é…å™¨) çš„æ€§èƒ½ä¸ Token æ¶ˆè€—å·®å¼‚ï¼Œå¹¶é¢„ç•™ç¼“å­˜ä¸å‹ç¼©æµ‹è¯•å•å…ƒã€‚\n",
    "\n",
    "åŒ…å«å†…å®¹:\n",
    "1. ç¯å¢ƒä¸å¯¼å…¥\n",
    "2. åŠ©æ‰‹æ„å»º (Baseline vs Enhanced)\n",
    "3. æµ‹è¯•æŸ¥è¯¢é›†å®šä¹‰\n",
    "4. A/B è¿è¡Œä¸åº¦é‡\n",
    "5. ç»“æœæ±‡æ€» (èŠ‚çœæ¯”ä¾‹)\n",
    "6. å ä½: ç¼“å­˜/å‹ç¼©/è¯­ä¹‰ç´¢å¼•åç»­è¡¥å……\n",
    "\n",
    "> æ³¨: è¿è¡Œå‰è¯·ç¡®è®¤å·²å®‰è£…å¿…è¦ä¾èµ– (LangChainã€Qwen/DeepSeek SDKã€Tavily æœç´¢ç­‰)ã€‚"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61eedb5f",
   "metadata": {},
   "source": [
    "## 1. å¯¼å…¥ä¸è¾…åŠ©ç±»å®šä¹‰"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3bafc929",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ” DASHSCOPE_API_KEY: å·²è®¾ç½®\n",
      "ğŸ” TAVILY_API_KEY: å·²è®¾ç½®\n",
      "âœ… deepagents å¯¼å…¥æˆåŠŸ: /Users/yf/Documents/GitHub/deepagents/deepagents_official/libs/deepagents/deepagents/__init__.py\n",
      "âœ… obsidian_assistant åŒ…å¯¼å…¥æˆåŠŸ\n",
      "âš ï¸ ä½¿ç”¨å ä½ TokenCounter\n",
      "âœ… ç¯å¢ƒä¸ä¾èµ–å¯¼å…¥å®Œæˆ (ä½¿ç”¨ path_utils)\n"
     ]
    }
   ],
   "source": [
    "# ç¯å¢ƒä¸è·¯å¾„é…ç½® + å¯¼å…¥ (ä½¿ç”¨å°è£… inject_deepagents_paths)\n",
    "import os, sys, time, json, importlib\n",
    "from pathlib import Path\n",
    "from typing import List, Dict\n",
    "\n",
    "# è·¯å¾„ä¸åŒ…ç¯å¢ƒç»Ÿä¸€æ³¨å…¥\n",
    "try:\n",
    "    from path_utils import inject_deepagents_paths\n",
    "    inject_deepagents_paths(verbose=False)\n",
    "except Exception as e:\n",
    "    print(f\"âš ï¸ è·¯å¾„æ³¨å…¥å¤±è´¥ fallback: {e}\")\n",
    "    cur = Path.cwd()\n",
    "    libs = cur / \"deepagents_official\" / \"libs\"\n",
    "    if libs.exists() and str(libs) not in sys.path:\n",
    "        sys.path.insert(0, str(libs))\n",
    "\n",
    "# ç¯å¢ƒå˜é‡åŠ è½½\n",
    "try:\n",
    "    from dotenv import load_dotenv\n",
    "    load_dotenv()\n",
    "except Exception:\n",
    "    pass\n",
    "\n",
    "print(\"ğŸ” DASHSCOPE_API_KEY:\", \"å·²è®¾ç½®\" if os.getenv(\"DASHSCOPE_API_KEY\") else \"æœªè®¾ç½®\")\n",
    "print(\"ğŸ” TAVILY_API_KEY:\", \"å·²è®¾ç½®\" if os.getenv(\"TAVILY_API_KEY\") else \"æœªè®¾ç½®\")\n",
    "\n",
    "# å¯¼å…¥ deepagents\n",
    "try:\n",
    "    import deepagents\n",
    "    from deepagents import create_deep_agent\n",
    "    print(\"âœ… deepagents å¯¼å…¥æˆåŠŸ:\", deepagents.__file__)\n",
    "except Exception as e:\n",
    "    print(\"âŒ deepagents å¯¼å…¥å¤±è´¥:\", e)\n",
    "\n",
    "# å¯¼å…¥ obsidian_assistant\n",
    "try:\n",
    "    import obsidian_assistant\n",
    "    from obsidian_assistant import create_obsidian_assistant_v2, get_model_adapter, SmartRouter\n",
    "    print(\"âœ… obsidian_assistant åŒ…å¯¼å…¥æˆåŠŸ\")\n",
    "except Exception as e:\n",
    "    print(\"âŒ obsidian_assistant å¯¼å…¥å¤±è´¥:\", e)\n",
    "    create_obsidian_assistant_v2 = None\n",
    "\n",
    "# TokenCounter\n",
    "try:\n",
    "    from obsidian_assistant.token_counter import TokenCounter\n",
    "except Exception:\n",
    "    class TokenCounter:\n",
    "        def __init__(self):\n",
    "            self.records = []\n",
    "        def start_counting(self):\n",
    "            pass\n",
    "    print(\"âš ï¸ ä½¿ç”¨å ä½ TokenCounter\")\n",
    "\n",
    "token_counter = TokenCounter()\n",
    "\n",
    "class PerformanceMonitor:\n",
    "    def __init__(self):\n",
    "        self.metrics = {\n",
    "            'total_queries': 0,\n",
    "            'total_time': 0.0,\n",
    "            'total_prompt_tokens': 0,\n",
    "            'total_completion_tokens': 0,\n",
    "            'total_cost': 0.0,\n",
    "            'web_queries': 0,\n",
    "            'local_queries': 0,\n",
    "        }\n",
    "        self.records = []\n",
    "\n",
    "    def log(self, route: str, usage: dict, elapsed: float):\n",
    "        m = self.metrics\n",
    "        m['total_queries'] += 1\n",
    "        m['total_time'] += elapsed\n",
    "        pt = usage.get('prompt_tokens', 0)\n",
    "        ct = usage.get('completion_tokens', 0)\n",
    "        m['total_prompt_tokens'] += pt\n",
    "        m['total_completion_tokens'] += ct\n",
    "        m['total_cost'] += usage.get('cost', 0.0)\n",
    "        if route == 'web_first':\n",
    "            m['web_queries'] += 1\n",
    "        else:\n",
    "            m['local_queries'] += 1\n",
    "        self.records.append({\n",
    "            'route': route,\n",
    "            'prompt_tokens': pt,\n",
    "            'completion_tokens': ct,\n",
    "            'total_tokens': usage.get('total_tokens', pt+ct),\n",
    "            'cost': usage.get('cost', 0.0),\n",
    "            'time': elapsed,\n",
    "        })\n",
    "\n",
    "    def report(self):\n",
    "        m = self.metrics\n",
    "        if m['total_queries'] == 0:\n",
    "            return {}\n",
    "        return {\n",
    "            'avg_time': m['total_time']/m['total_queries'],\n",
    "            'avg_prompt_tokens': m['total_prompt_tokens']/m['total_queries'],\n",
    "            'avg_completion_tokens': m['total_completion_tokens']/m['total_queries'],\n",
    "            'avg_total_tokens': (m['total_prompt_tokens']+m['total_completion_tokens'])/m['total_queries'],\n",
    "            'avg_cost': m['total_cost']/m['total_queries'],\n",
    "            'web_ratio': m['web_queries']/m['total_queries'],\n",
    "        }\n",
    "\n",
    "print('âœ… ç¯å¢ƒä¸ä¾èµ–å¯¼å…¥å®Œæˆ (ä½¿ç”¨ path_utils)')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ad395b4",
   "metadata": {},
   "source": [
    "## 2. æ„å»ºåŠ©æ‰‹å®ä¾‹ (Baseline vs Enhanced)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16c0497e",
   "metadata": {},
   "outputs": [],
   "source": [
    "OBSIDIAN_PATH = './vault'  # æ›¿æ¢ä¸ºçœŸå®è·¯å¾„\n",
    "MODEL_NAME = 'qwen-turbo'\n",
    "\n",
    "# å¯é€‰ï¼šè®¾ç½®ç¯å¢ƒå˜é‡æ§åˆ¶è¯¦ç»†æ—¥å¿—\n",
    "os.environ['OBSIDIAN_ASSISTANT_VERBOSE'] = '0'  # '1' / 'true' å¯å¼€å¯åˆ›å»ºé˜¶æ®µè¯¦ç»†è¾“å‡º\n",
    "\n",
    "# Baseline: ç¦ç”¨é€‚é…å™¨ & è·¯ç”± (é™é»˜)\n",
    "baseline = create_obsidian_assistant_v2(\n",
    "    docs_path=OBSIDIAN_PATH,\n",
    "    model_name=MODEL_NAME,\n",
    "    enable_model_adapter=False,\n",
    "    enable_smart_routing=False,\n",
    "    verbose=False,\n",
    " )\n",
    "\n",
    "# Enhanced: å¯ç”¨é€‚é…å™¨ & è·¯ç”± (ç”± env æ§åˆ¶)\n",
    "enhanced = create_obsidian_assistant_v2(\n",
    "    docs_path=OBSIDIAN_PATH,\n",
    "    model_name=MODEL_NAME,\n",
    "    enable_model_adapter=True,\n",
    "    enable_smart_routing=True,\n",
    "    verbose=None,  # None -> è¯»å–ç¯å¢ƒå˜é‡\n",
    " )\n",
    "\n",
    "print('åŠ©æ‰‹å®ä¾‹æ„å»ºå®Œæˆ -> baseline / enhanced')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2fcc6f7",
   "metadata": {},
   "source": [
    "## 3. å®šä¹‰æµ‹è¯•æŸ¥è¯¢é›†"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77f5f9eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_queries = [\n",
    "    'å¦‚ä½•åˆ›å»ºåŒå‘é“¾æ¥ï¼Ÿ',\n",
    "    'æœ€æ–°çš„ Obsidian æ’ä»¶æ¨èæœ‰å“ªäº›ï¼Ÿ',\n",
    "    'è¯·æ€»ç»“æˆ‘ç¬”è®°é‡Œå…³äºä»»åŠ¡ç®¡ç†çš„æœ€ä½³å®è·µ',\n",
    "    '2025 å¹´ AI ç¬”è®°å·¥ä½œæµè¶‹åŠ¿æ˜¯ä»€ä¹ˆï¼Ÿ',\n",
    "    'æ€æ ·åœ¨æœ¬åœ°åº“ä¸­æŸ¥æ‰¾å¼•ç”¨æœªä½¿ç”¨çš„ç¬”è®°ï¼Ÿ',\n",
    "    'ç”Ÿæˆä¸€ä¸ªå…³äºæˆ‘ Obsidian æ¯æ—¥å›é¡¾çš„æ¨¡æ¿ç¤ºä¾‹',\n",
    "    'æ¨èç°åœ¨æœ€æ´»è·ƒçš„çŸ¥è¯†ç®¡ç†ç¤¾åŒº',\n",
    "    'ç¬”è®°é“¾æ¥ç»“æ„ä¼˜åŒ–çš„æ­¥éª¤',\n",
    "    'ä»Šå¹´æœ‰å“ªäº›æ–°ç‰¹æ€§å€¼å¾—å…³æ³¨',\n",
    "    'æ€»ç»“ markdown ä¸­è¡¨æ ¼å¿«é€Ÿç¼–è¾‘æŠ€å·§'\n",
    "]\n",
    "len(test_queries)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74ec000a",
   "metadata": {},
   "source": [
    "## 4. A/B è¿è¡Œé€»è¾‘å®šä¹‰"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "973ad5e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "baseline_monitor = PerformanceMonitor()\n",
    "enhanced_monitor = PerformanceMonitor()\n",
    "\n",
    "baseline_results = []\n",
    "enhanced_results = []\n",
    "\n",
    "coverage_values_baseline = []\n",
    "coverage_values_enhanced = []\n",
    "\n",
    "source_counts_baseline = []\n",
    "source_counts_enhanced = []\n",
    "\n",
    "def run_structured(assistant, query: str):\n",
    "    start = time.time()\n",
    "    result = assistant.invoke({\"messages\": [(\"user\", query)]})\n",
    "    elapsed = time.time() - start\n",
    "    answer = result.get('answer')\n",
    "    route = result.get('route_strategy') or 'n/a'\n",
    "    usage = result.get('token_usage', {})\n",
    "    coverage = result.get('route_coverage')\n",
    "    time_sensitive = result.get('time_sensitive')\n",
    "    sources = result.get('sources', [])\n",
    "    return {\n",
    "        'query': query,\n",
    "        'answer': answer,\n",
    "        'route': route,\n",
    "        'elapsed': elapsed,\n",
    "        'usage': usage,\n",
    "        'coverage': coverage,\n",
    "        'time_sensitive': time_sensitive,\n",
    "        'sources': sources,\n",
    "        'total_tokens': usage.get('total_tokens'),\n",
    "        'cost': usage.get('cost'),\n",
    "    }\n",
    "\n",
    "for q in test_queries:\n",
    "    b = run_structured(baseline, q)\n",
    "    baseline_monitor.log(b['route'], b['usage'], b['elapsed'])\n",
    "    baseline_results.append(b)\n",
    "    if b['coverage'] is not None:\n",
    "        coverage_values_baseline.append(b['coverage'])\n",
    "    source_counts_baseline.append(len(b['sources']))\n",
    "\n",
    "    e = run_structured(enhanced, q)\n",
    "    enhanced_monitor.log(e['route'], e['usage'], e['elapsed'])\n",
    "    enhanced_results.append(e)\n",
    "    if e['coverage'] is not None:\n",
    "        coverage_values_enhanced.append(e['coverage'])\n",
    "    source_counts_enhanced.append(len(e['sources']))\n",
    "\n",
    "print('æµ‹è¯•å®Œæˆ: å…±è¿è¡Œ', len(test_queries), 'æ¡æŸ¥è¯¢')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ff2bdfd",
   "metadata": {},
   "source": [
    "## 5. æ±‡æ€»å¯¹æ¯”ç»“æœ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d74df6bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "baseline_report = baseline_monitor.report()\n",
    "enhanced_report = enhanced_monitor.report()\n",
    "\n",
    "import json, statistics\n",
    "\n",
    "avg_coverage_baseline = statistics.mean(coverage_values_baseline) if coverage_values_baseline else None\n",
    "avg_coverage_enhanced = statistics.mean(coverage_values_enhanced) if coverage_values_enhanced else None\n",
    "avg_sources_baseline = statistics.mean(source_counts_baseline) if source_counts_baseline else 0\n",
    "avg_sources_enhanced = statistics.mean(source_counts_enhanced) if source_counts_enhanced else 0\n",
    "\n",
    "comparison = {\n",
    "    'baseline': baseline_report,\n",
    "    'enhanced': enhanced_report,\n",
    "    'tokens_reduction_pct': (\n",
    "        f\"{(baseline_report.get('avg_total_tokens',0)-enhanced_report.get('avg_total_tokens',0))/baseline_report.get('avg_total_tokens',1)*100:.1f}%\"\n",
    "        if baseline_report.get('avg_total_tokens') else 'n/a'\n",
    "    ),\n",
    "    'cost_reduction_pct': (\n",
    "        f\"{(baseline_report.get('avg_cost',0)-enhanced_report.get('avg_cost',0))/baseline_report.get('avg_cost',1)*100:.1f}%\"\n",
    "        if baseline_report.get('avg_cost') else 'n/a'\n",
    "    ),\n",
    "    'web_ratio_change_pct': (\n",
    "        f\"{(baseline_report.get('web_ratio',0)-enhanced_report.get('web_ratio',0))/baseline_report.get('web_ratio',1)*100:.1f}%\"\n",
    "        if baseline_report.get('web_ratio') else 'n/a'\n",
    "    ),\n",
    "    'avg_coverage_baseline': avg_coverage_baseline,\n",
    "    'avg_coverage_enhanced': avg_coverage_enhanced,\n",
    "    'coverage_change_pct': (\n",
    "        f\"{((avg_coverage_baseline or 0)-(avg_coverage_enhanced or 0))/(avg_coverage_baseline or 1)*100:.1f}%\" if avg_coverage_baseline else 'n/a'\n",
    "    ),\n",
    "    'avg_sources_baseline': avg_sources_baseline,\n",
    "    'avg_sources_enhanced': avg_sources_enhanced,\n",
    "    'sources_change_pct': (\n",
    "        f\"{(avg_sources_baseline-avg_sources_enhanced)/avg_sources_baseline*100:.1f}%\" if avg_sources_baseline else 'n/a'\n",
    "    )\n",
    "}\n",
    "json.dumps(comparison, ensure_ascii=False, indent=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60ab9a21",
   "metadata": {},
   "source": [
    "## 6. ç¼“å­˜ / å‹ç¼© / è¯­ä¹‰ç´¢å¼•åç»­æ‰©å±•å ä½\n",
    "\n",
    "åç»­åŠŸèƒ½ä¸Šçº¿ååœ¨æ­¤è¡¥å……æµ‹è¯•å•å…ƒ: \n",
    "- ç¼“å­˜å‘½ä¸­ç‡å¯¹æ¯” (é¦–æ¬¡ vs é‡å¤æŸ¥è¯¢)\n",
    "- ç½‘é¡µç»“æœå‹ç¼©å‰å token å¯¹æ¯”\n",
    "- è¯­ä¹‰ç¼“å­˜ç›¸ä¼¼åº¦è§¦å‘æµ‹è¯•\n",
    "\n",
    "å¯æ–°å¢å•å…ƒ: `run_cache_trials()` ä¸ `measure_compression()`ã€‚"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e1ce0de",
   "metadata": {},
   "source": [
    "## 7. åˆæ­¥ç»“è®ºä¸æ”¹è¿›å»ºè®® (è¿è¡Œåå¡«å†™)\n",
    "\n",
    "- Tokens å¹³å‡é™ä½: (å¾…è¿è¡Œ)\n",
    "- æˆæœ¬å¹³å‡é™ä½: (å¾…è¿è¡Œ)\n",
    "- Web æœç´¢æ¯”ä¾‹å˜åŒ–: (å¾…è¿è¡Œ)\n",
    "\n",
    "ä¸‹ä¸€æ­¥: \n",
    "1. æ¥å…¥ç¼“å­˜å±‚å¹¶åœ¨æœ¬ Notebook å¢åŠ ç¼“å­˜å¯¹æ¯”å•å…ƒã€‚\n",
    "2. æ¥å…¥ç»“æœå‹ç¼©å™¨å¹¶è®°å½•å‹ç¼©ç‡ã€‚\n",
    "3. å¼•å…¥çœŸå® token ç»Ÿè®¡æ›¿æ¢ rough ä¼°ç®—ã€‚"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv (3.13.5)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
